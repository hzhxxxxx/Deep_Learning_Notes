
- 1，一个手写数字minst_cnn识别的实现：
	总文件夹下：
	训练手写数字识别mnist_cnn_augmented.py
	模型：mnist_cnn_augmented.pth
	窗口测试手写数字mnist_cnn_augmented.py


- 2，一些常用的提高精度的方法
	1，*data augmentation(数据扩充)*：人为地扩充输入的训练图像。对于输入图像，通过施加旋转，或是在垂直，水平方向上进行微笑的移动，增加输入图像的种类。（注意其实不是算是增加训练图像，因为一般训练会有几个周期，每个周期里其实读的都是一样的图像，而加入了数据扩充，就是每个周期读到不同的图像）
	2，*增加网络深度*：因为深层神经网络中，每层的神经元各司其职，因此如果识别一些复杂图像的时候，层数过浅，会导致每层神经元要学习的内容过大，导致学习效果不好。通过加深神经元层次分层次降低每层压力地传递信息。
	3，其它的常见优化方法见[[2优化提高精度的方法]]


- 3，常见的基于CNN的网络：
	
	1，VGG：特点是*卷积层会重复地叠加2次到4次，再通过池化层将大小减半的处理*。
	
	2，GoogleNet：特点是*其在横向是也有宽度，每层使用多个大小不同的滤波器，最后再合并他们的结果*
	
	3，ResNet：特点是*快捷结构*，这里必须提到一个概念是*深度过深，导致梯度消失学习效率下降*的概念
	神经网络会在层数过多的时候，出现误差变大，学习能力下降的问题。
	而ResNet通过引入”跳层传输“的快捷结构，这样就可以在加深网络层数的情况下，同时变相地”减少“了网络层数，保持一个平衡。


- 4，使用gpu学习可以高效地加速训练的效率。以及使用多个gpu进行分布式学习
	顺带提一嘴，pytorch是深度学习必须的一个库，cuda是连接使用gpu进行学习的一个东西，anaconda是可以创建一个隔离环境的箱子。


- 5，物体检测（在图片中框出目标物体）：
	R-CNN方法：
	1，先进行候选区域的选取（与深度学习无关），会把整个图片”拆分“成好多个小图片
	2，然后把这好多个小图片作为输入的测试数据，放入已经针对目标物体识别的训练好的模型中，进行一个检测识别。

- 6，图像物体分割（在图片中描出目标物体）（物体检测plus版）
	FCN方法：
	全使用卷积层。
	因为图像物体分割，不仅知道"有什么"，还要知道"在哪里"，重点是目标物体在图片中的位置信息。而使用全连接层会丢失位置信息，所以全部使用卷积层，保留位置信息。

- 7，图像标题的生成（给出一个图像后，自动生成表示该图片信息的文本）：
	NIC方法：
	其实就是结合CNN图像识别+自然语言处理
	先通过CNN图像识别识别出一个特征物体名字，然后通过自然语言处理生成一个连贯的相关文本。结合图像识别和自然语言处理叫做”多模态处理“，ai读照片进行内容的思考也叫多模态能力。

- 8，图像风格变换：
	引入风格矩阵，在学习的过程中不断减少与风格矩阵的偏差，使得图片逐渐接近目标风格。

- 9，图像的生成：
	现在很多ai都可以进行图像的生成，实际就是一个已经训练了大量图像的模型可以生成一个新的图片。
	提一嘴，我们之前说的手写数字照片的学习叫做*监督学习*，也就是“有标签的学习”，每一张照片都对应一个明确的标签。
	而图像的生成这种单纯喂各种图像的学习叫做*无监督学习*，也就是”无标签的学习“，每个图片都没有明确的信息，给你一堆没有说明的杂乱数据（一大堆图，不告诉你这是什么），任务是自己摸索发现资料的内部规律。


